%-------------------------------------------------------
%-- PREAMBLE
%-------------------------------------------------------
\documentclass[a4paper,10pt]{article} % Uses article class in A4 format

% Includes preamble configurations
\input{theme/assignment_preamble.tex}

% --------------------------------------------------------------------
% *************************** FRONT MATTER ***************************
% --------------------------------------------------------------------
\def\assnumber{12}
\def\title{Tensor Train Singular Value Decomposition (TTSVD)}
\def\author{Otacílio B. L. Neto}
\def\authorid{481736}
\def\email{minhotmog@alu.ufc.br}
\def\institute{Universidade Federal do Ceará}
\def\course{TIP8419 - Tensor Algebra}
\def\professor{Prof. André A., Prof. Maryam D.} 

% ====================================================================

% --------------------------------------------------------------------
% ***************************** DOCUMENT *****************************
% --------------------------------------------------------------------
\begin{document} \sloppy

%-------------------------------------------------------
% TITLE PAGE
%-------------------------------------------------------
\thetitle

%-------------------------------------------------------
% PROBLEM 1
%-------------------------------------------------------
\vskip-0.4cm
\begin{problem} \justifying
We will go to implement the TT-SVD (Tensor Train Singular Value Decomposition) algorithm. The TT Decomposition of a $N$-order tensor $\mathcal{X} \in \mathbb{R}^{I_1\times I_2 \times \cdots \times I_N}$, with TT-Ranks ($R_1, R_2, \cdots, R_{N-1}$), is a decomposition of the tensor $\mathcal{X}$ into a train of tensors as 
\begin{equation*}
    \mathcal{X} = \mathbf{G}_1 \times_2^1 \mathcal{G}_2 \times_3^1 \mathcal{G}_3  \times_4^1 \cdots \times_{N-1}^1 \mathcal{G}_{N-1} \times_{N}^1 \mathbf{G}_N.
\end{equation*}

\noindent For a $4$-order tensor $\mathcal{X} \in \mathbb{R}^{5\times 5\times 5\times 5}$, implement the TT-SVD algorithm to estimate the TT-cores $\mathbf{G}_1 \in \mathbb{C}^{5\times R_1}$, $\mathcal{G}_2 \in \mathbb{C}^{R_{1}\times 5\times R_2}$, $\mathcal{G}_3 \in \mathbb{C}^{R_{2}\times 5\times R_3}$, and $\mathbf{G}_4 \in \mathbb{C}^{R_3 \times 5}$ that forms the TT Decomposition of $\mathcal{X}$, for given ranks ($R_1,R_2,R_3$). For randomly generated ($\mathbf{G}_1, \mathcal{G}_2, \mathcal{G}_3, \mathbf{G}_4$), compare the original tensor $\mathcal{X}$ with the one reconstructed by the TT-SVD.

\end{problem}

\begin{solution} \justifying

\noindent The function is implemented in Julia (v1.4), and is shown in Listing \ref{lst: code1}.  Regarding the present implementation, lines 2--14 define an auxiliary function to compute the tensor train products. The Train Tensor Singular Value Decomposition (TT-SVD) algorithm is then implemented in lines 17--237, following the pseudocode provided in the course material. 

\begin{code}[0.95\textwidth]{The Tensor-Train Singular Value Decomposition (TTSVD) algorithm for Problem 1.}{lst: code1}
# ==== FUNCTIONS ====
# The Tensor-Train product function
function ×¹(G...)
    # Auxiliary variables with dimension/rank information
    IR  = [size(G[1]); [size(G[i])[2:end] for i=2:length(G)]...]
    I,R = ([IR[i][1] for i=1:length(G)], [IR[i][2] for i=1:length(G)-1])
    
    # Tensor-train product loop
    𝓧 = zeros(I...)
    for i in CartesianIndices(𝓧), r in CartesianIndices((R[1],R[2],R[3]))
        𝓧[i] += G[1][i[1],r[1]]*G[2][r[1],i[2],r[2]]*G[3][r[2],i[3],r[3]]*G[4][r[3],i[4]]
    end
    return 𝓧    # Returns the resulting tensor
end

# The Tensor-Train Singular Value Decomposition (TTSVD) algorithm
function TTSVD(𝓧)
    I = size(𝓧)                                     # Auxiliary variable
                                                    #
    X¹ = reshape(𝓧, (I[1],Π(I[2:4])))               # Unfolds the tensor [𝓧]₁ ∈ ℝ(I₁,I₂I₃I₄)
    U,Σ,V = svd(X¹);    Σ = Diagonal(Σ);            # Computes the SVD [𝓧]₁ = UΣVᴴ
    R₁ = sum(diag(Σ) .> 1e-6)                       # Gets the number of nonzero singular-values
    U₁ = U[:,1:R₁];  V₁ = (Σ*(V)ᴴ)[1:R₁,:]          # Truncates pair (U,V) given R₁
    G₁ = U₁                                         # Stores the 1st factor G₁ ∈ ℝ(I₁,R₁)
                                                    #
    X² = reshape(V₁, (R₁*I[2], Π(I[3:4])))          # Unfolds the matrix X² = [V₁]₁ ∈ ℝ(R₁I₂,I₃I₄)
    U,Σ,V = svd(X²);    Σ = Diagonal(Σ);            # Computes the SVD X² = UΣVᴴ
    R₂ = sum(diag(Σ) .> 1e-6)                       # Gets the number of nonzero singular-values
    U₂ = U[:,1:R₂];  V₂ = (Σ*(V)ᴴ)[1:R₂,:]          # Truncates pair (U,V) given R₂
    𝓖₂ = reshape(U₂, (R₁, I[2], R₂))                # Reshapes the 2nd factor 𝓖₂ ∈ ℝ(R₁,I₂,R₂)
                                                    # 
    X³ = reshape(V₂, (R₂*I[3], I[4]))               # Unfolds the matrix X³ = [V₂]₁ ∈ ℝ(R₂I₃,I₄)
    U,Σ,V = svd(X³);    Σ = Diagonal(Σ);            # Computes the SVD X³ = UΣVᴴ
    R₃ = sum(diag(Σ) .> 1e-6)                       # Gets the number of nonzero singular-values
    U₃ = U[:,1:R₃];  V₃ = (Σ*(V)ᴴ)[1:R₃,:]          # Truncates pair (U,V) given R₃
    𝓖₃ = reshape(U₃, (R₂, I[3], R₃))                # Reshapes the 3rd factor 𝓖₃ ∈ ℝ(R₂,I₃,R₃)
    G₄ = V₃[1:R₃,:]                                 # Stores the 4th factor G₄ ∈ ℝ(R₃,I₄)

    return (G₁, 𝓖₂, 𝓖₃, G₄)                         # Returns the decomposition factors
end
    
\end{code} 

The function $\times^1(\cdot)$ implements the element-wise TT decomposition through the formula
$$
    x_{i_1,i_2,\cdots,i_N} = \sum_{r_1 = 1}^{R_1} \sum_{r_2 = 1}^{R_2} \sum_{r_3 = 1}^{R_3} \cdots \sum_{r_{N-2} = 1}^{R_{N-2}} \sum_{r_{N-1} = 1}^{R_{N-1}} \mathbf{G}_{1_{i_1,r_1}} \mathcal{G}_{2_{r_1,i_2,r_2}} \mathcal{G}_{3_{r_2,i_3,r_3}} \cdots \mathcal{G}_{{N-1}_{r_{N-2},i_{N-1},r_{N-1}}} \mathbf{G}_{N_{r_N,i_{N-1}}}.
$$
The TT-SVD algorithm follows the procedure described by the tensor network shown in Fig. \ref{fig: f1}

\begin{figure}[ht] \centering
    \includegraphics[width=0.9\textwidth]{imgs/TensorNetwork.pdf}
    \caption{Illustration of the TT-SVD algorithm using a Tensor Network framework.}
    \label{fig: f1}
\end{figure}

The implementation is tested through the script presented at Listing \ref{lst: code2}.
The execution of the assertion tests at lines 10 and 18 do not result in any failed assertion, thus indicating that the function outputs the expected results for the given tests. Specifically, executing lines 11 and 19 shows that, on average, $\| \mathcal{X} - \hat{\mathcal{X}} \|_F^2 \approx 1.2\cdot10^{-26}$ for $\hat{\mathcal{X}} = \hat{\mathbf{G}}_1 \times_2^1 \hat{\mathcal{G}}_2 \times_3^1 \hat{\mathcal{G}}_{3} \times_{4}^1 \hat{\mathbf{G}}_4$ with all TT-cores obtained from the TT-SVD. Thus, it is possible to conclude that factors $(\hat{\mathbf{G}}_1, \hat{\mathcal{G}}_2, \hat{\mathcal{G}}_3, \hat{\mathbf{G}}_4)$ comprise a valid decomposition of the original tensor $\mathcal{X}$. 

\begin{code}[0.9\textwidth]{Script used to test the TTSVD algorithm implementation.}{lst: code2}
# ==== SCRIPT ====
# -- Case 1: Generating 𝓧 from factors (G₁, 𝓖₂, 𝓖₃, G₄) --
# Randomly generates the TT factors and computes the tensor 𝓧 = G₁ ×¹ 𝓖₂ ×¹ 𝓖₃ ×¹ G₄
R = [4 3 4];     # Ranks used for the decomposition
G₁ = randn(5,R[1]); 𝓖₂ = randn(R[1],5,R[2]); 𝓖₃ = randn(R[2],5,R[3]); G₄ = randn(R[3],5);
𝓧 = ×¹(G₁, 𝓖₂, 𝓖₃, G₄);

G₁_, 𝓖₂_, 𝓖₃_, G₄_ = TTSVD(𝓧);      # Estimates the factors (G₁, 𝓖₂, 𝓖₃, G₄)

@assert 𝓧 ≈ ×¹(G₁_, 𝓖₂_, 𝓖₃_, G₄_)
@show norm(𝓧 - ×¹(G₁_, 𝓖₂_, 𝓖₃_, G₄_))^2

# -- Case 2: Directly generating 𝓧 randomly --
𝓧 = randn(5, 5, 5, 5);

G₁_, 𝓖₂_, 𝓖₃_, G₄_ = TTSVD(𝓧);      # Estimates the factors (G₁, 𝓖₂, 𝓖₃, G₄)

@assert 𝓧 ≈ ×¹(G₁_, 𝓖₂_, 𝓖₃_, G₄_)
@show norm(𝓧 - ×¹(G₁_, 𝓖₂_, 𝓖₃_, G₄_))^2

# ==== ====
\end{code} 

Moreover, we verified that the resulting estimated tensors $(\hat{\mathbf{G}}_1, \hat{\mathcal{G}}_2, \hat{\mathcal{G}}_3, \hat{\mathbf{G}}_4)$ are not actually good approximations of the original factors used to generate $\mathcal{X}$. In fact, we have average distances of 
$$
    \| \mathbf{G}_1 - \hat{\mathbf{G}}_1 \|_F^2 = 25.1,\ \ \  
    \| \mathcal{G}_2 - \hat{\mathcal{G}}_2 \|_F^2 = 61.7,\ \ \ 
    \| \mathcal{G}_3 - \hat{\mathcal{G}}_3 \|_F^2 = 62.6,\ \ \ 
    \| \mathbf{G}_4 - \hat{\mathbf{G}}_4 \|_F^2 = 3\cdot 10^4. 
$$
This result is expected, since the decomposition is not unique: is always possible to replace a pair of successive TT-cores $\mathcal{G}_j$ and $\mathcal{G}_{j+1}$ by $\tilde{\mathcal{G}}_j = \mathcal{G}_j \times_{3}^1 \mathbf{M}_j^{-1}$ and $\tilde{\mathcal{G}}_{j+1} = \mathbf{M}_j \times_{2}^1 \mathcal{G}_{j+1}$ without changing the resulting tensor $\mathcal{X}$.

\end{solution}
\vskip0.5cm

%-------------------------------------------------------
\end{document}
